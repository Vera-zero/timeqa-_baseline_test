## ğŸ“ é¡¹ç›®ç»“æ„

```
ETE-Graph/
â”œâ”€â”€ DyG-RAG/                      # DyG-RAG æ ¸å¿ƒå®ç°
â”‚   â”œâ”€â”€ graphrag/                 # æºä»£ç 
â”‚   â”œâ”€â”€ examples/                 # ä½¿ç”¨ç¤ºä¾‹
â”‚   â”‚   â”œâ”€â”€ timeqa_run.py
â”‚   â”‚   â””â”€â”€ temreason_run.py
â”‚   â”œâ”€â”€ reproduce/                # è®ºæ–‡å¤ç°è„šæœ¬
â”‚   â”‚   â”œâ”€â”€ timeqa.py
â”‚   â”‚   â”œâ”€â”€ tempreason.py
â”‚   â”‚   â””â”€â”€ complextr.py
â”‚   â””â”€â”€ models/                   # æ¨¡å‹ä¸‹è½½è„šæœ¬
â”œâ”€â”€ GraphRAG/                     # GraphRAG åŸºçº¿æ–¹æ³•
â”‚   â”œâ”€â”€ Option/                   # é…ç½®æ–‡ä»¶
â”‚   â”‚   â”œâ”€â”€ Config2.yaml          # å…¨å±€é…ç½®
â”‚   â”‚   â””â”€â”€ Method/               # æ–¹æ³•é…ç½®
â”‚   â”‚       â”œâ”€â”€ LGraphRAG.yaml
â”‚   â”‚       â”œâ”€â”€ GGraphRAG.yaml
â”‚   â”‚       â”œâ”€â”€ HippoRAG.yaml
â”‚   â”‚       â”œâ”€â”€ LightRAG.yaml
â”‚   â”‚       â””â”€â”€ RAPTOR.yaml
â”‚   â”œâ”€â”€ Core/                     # æ ¸å¿ƒå®ç°
â”‚   â”œâ”€â”€ Data/                     # æ•°æ®åŠ è½½å™¨
â”‚   â””â”€â”€ main.py                   # ä¸»å…¥å£ (å¾…æ·»åŠ )
â”œâ”€â”€ dataset/                      # æ•°æ®é›†æ–‡ä»¶
â”‚   â”œâ”€â”€ timeqa/
â”‚   â”‚   â””â”€â”€ test_processed.json
â”‚   â””â”€â”€ tempreason/
â”œâ”€â”€ QA-result/                    # QAç³»ç»Ÿè¾“å‡ºç»“æœ
â”‚   â”œâ”€â”€ timeqa/
â”‚   â”‚   â”œâ”€â”€ DyG-RAG/
â”‚   â”‚   â””â”€â”€ HippoRAG/
â”‚   â””â”€â”€ tempreason/
â”œâ”€â”€ evaluation_results/           # è¯„ä¼°è¾“å‡º
â”œâ”€â”€ evaluate_qa_results.py        # è¯„ä¼°è„šæœ¬
â”œâ”€â”€ graph_baseline.md             # åŸºçº¿é…ç½®æ–‡æ¡£
â”œâ”€â”€ change.md                     # ä¿®æ”¹è®°å½•
â””â”€â”€ README.md                     # æœ¬æ–‡ä»¶
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒé…ç½®

#### å®‰è£…ä¾èµ–

```bash
# åˆ›å»º conda ç¯å¢ƒ
conda create -n ete-graph python=3.10
conda activate ete-graph

# å®‰è£…é¡¹ç›®ä¾èµ–
cd /workspace/ETE-Graph
pip install -r requirements.txt
```

#### ä¸‹è½½å¿…éœ€æ¨¡å‹

```bash
# DyG-RAG æ‰€éœ€æ¨¡å‹ (NER å’Œ Cross-Encoder)
cd DyG-RAG/models
python download.py
```

### 2. å¯åŠ¨æœ¬åœ° LLM æœåŠ¡

ä½¿ç”¨ vLLM å¯åŠ¨ Qwen3-32B æ¨¡å‹æœåŠ¡:

```bash
# æ–¹å¼1: å• GPU
python -m vllm.entrypoints.openai.api_server \
    --model /workspace/models/Qwen3-32B \
    --served-model-name qwen3-32b \
    --host 0.0.0.0 \
    --port 8000 \
    --max-model-len 32768

# æ–¹å¼2: å¤š GPU (å¼ é‡å¹¶è¡Œ)
CUDA_VISIBLE_DEVICES=2,3 python -m vllm.entrypoints.openai.api_server \
    --model /workspace/models/Qwen3-32B \
    --served-model-name qwen3-32b \
    --host 0.0.0.0 \
    --port 8000 \
    --tensor-parallel-size 2 \
    --max-model-len 32768 \
    --dtype bfloat16 \
    --gpu-memory-utilization 0.85
```

### 3. è¿è¡Œç¤ºä¾‹

#### DyG-RAG å¿«é€Ÿç¤ºä¾‹

```bash
# è¿è¡Œ TimeQA æ•°æ®é›†ç¤ºä¾‹
cd DyG-RAG/examples
python timeqa_run.py

# è¿è¡Œ TempReason æ•°æ®é›†ç¤ºä¾‹
python temreason_run.py
```

#### GraphRAG æ–¹æ³•è¿è¡Œ

```bash
# è¿è¡Œ HippoRAG æ–¹æ³•
cd GraphRAG
python main.py -opt Option/Method/HippoRAG.yaml \
               -dataset_name timeqa \
               -data_root /workspace/ETE-Graph/dataset

# è¿è¡Œ LightRAG æ–¹æ³•
python main.py -opt Option/Method/LightRAG.yaml \
               -dataset_name tempreason \
               -data_root /workspace/ETE-Graph/dataset

# è¿è¡Œ LGraphRAG (Local search)
python main.py -opt Option/Method/LGraphRAG.yaml \
               -dataset_name timeqa

# è¿è¡Œ GGraphRAG (Global search)
python main.py -opt Option/Method/GGraphRAG.yaml \
               -dataset_name timeqa
```

## ğŸ“Š è¯„ä¼°å·¥å…·

### è¯„ä¼°æ‰€æœ‰ QA ç»“æœ

```bash
cd /workspace/ETE-Graph
python evaluate_qa_results.py
```

è¯„ä¼°å®Œæˆå,ç»“æœå°†ä¿å­˜åœ¨ `evaluation_results/` ç›®å½•:
- `results_table.md` - Markdown æ ¼å¼çš„è¯„ä¼°è¡¨æ ¼
- `results_table.csv` - CSV æ ¼å¼çš„è¯„ä¼°è¡¨æ ¼

### é«˜çº§è¯„ä¼°é€‰é¡¹

```bash
# ä»…è¯„ä¼°ç‰¹å®šæ•°æ®é›†
python evaluate_qa_results.py --dataset timeqa

# ä»…è¯„ä¼°ç‰¹å®šæ–¹æ³•
python evaluate_qa_results.py --method HippoRAG

# æŒ‡å®šè¾“å‡ºæ ¼å¼
python evaluate_qa_results.py --output-format markdown

# è‡ªå®šä¹‰è·¯å¾„
python evaluate_qa_results.py \
    --qa-result-dir /path/to/QA-result \
    --dataset-dir /path/to/dataset \
    --output-dir /path/to/output
```

### è¯„ä¼°æŒ‡æ ‡

- **EM (Exact Match)**: ç²¾ç¡®åŒ¹é…ç‡ - é¢„æµ‹ç­”æ¡ˆä¸æ ‡å‡†ç­”æ¡ˆå®Œå…¨åŒ¹é…çš„æ¯”ä¾‹
- **F1 Score**: Token çº§åˆ«çš„ F1 åˆ†æ•° - è¡¡é‡é¢„æµ‹ç­”æ¡ˆä¸æ ‡å‡†ç­”æ¡ˆçš„é‡å ç¨‹åº¦

è¯¦ç»†è¯„ä¼°è¯´æ˜è¯·å‚è€ƒ[è¯„ä¼°æ–‡æ¡£](#è¯„ä¼°æŒ‡æ ‡è¯´æ˜)ã€‚

## ğŸ“– DyG-RAG è¯¦ç»†è¯´æ˜

### DyG-RAG æ ¸å¿ƒåˆ›æ–°

1. **é¦–ä¸ªåŠ¨æ€å›¾ç»“æ„**: ä»äº‹ä»¶ä¸­å¿ƒè§†è§’æ„å»ºå’Œå­˜å‚¨æ—¶åºæ–‡æœ¬çŸ¥è¯†
2. **äº‹ä»¶ç²’åº¦æ˜¾å¼æ—¶åºç¼–ç **: æå‡ºåŠ¨æ€äº‹ä»¶å•å…ƒ(DEU)ç²’åº¦,åœ¨çŸ¥è¯†ç»„ç»‡é˜¶æ®µæ˜¾å¼åµŒå…¥æ—¶åºä¿¡æ¯
3. **RAG-æ¨ç†é›†æˆ**: è‡ªç„¶æ”¯æŒæ£€ç´¢å¢å¼ºç”Ÿæˆä¸æ—¶åºæ¨ç†çš„é›†æˆ,å¯ç”¨ Time-CoT prompting
4. **å®éªŒéªŒè¯**: åœ¨ä¸‰ç§ä¸åŒç±»å‹çš„æ—¶åºé—®ç­”æ•°æ®é›†ä¸ŠéªŒè¯äº†ä¼˜è¶Šæ€§èƒ½

### DyG-RAG æ¶æ„

<details>
<summary>æŸ¥çœ‹æ¶æ„å›¾</summary>

DyG-RAG çš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬:
- **äº‹ä»¶æŠ½å–ä¸æ—¶åºç¼–ç **: ä»æ–‡æœ¬ä¸­æŠ½å–äº‹ä»¶å¹¶ç¼–ç æ—¶åºä¿¡æ¯
- **åŠ¨æ€å›¾æ„å»º**: æ„å»ºäº‹ä»¶ä¸­å¿ƒçš„åŠ¨æ€çŸ¥è¯†å›¾è°±
- **æ—¶åºæ„ŸçŸ¥æ£€ç´¢**: åŸºäºæ—¶åºçº¦æŸçš„ç›¸å…³äº‹ä»¶æ£€ç´¢
- **Time-CoT æ¨ç†**: é›†æˆæ—¶åºé“¾å¼æ¨ç†çš„ç­”æ¡ˆç”Ÿæˆ

è¯¦ç»†æ¶æ„è¯·å‚è€ƒ [DyG-RAG README](DyG-RAG/README.md) å’Œ[è®ºæ–‡](https://www.arxiv.org/abs/2507.13396)ã€‚
</details>

### è®ºæ–‡å¤ç°

```bash
cd DyG-RAG/reproduce

# TimeQA æ•°æ®é›†å¤ç°
python timeqa.py

# TempReason æ•°æ®é›†å¤ç°
python tempreason.py

# ComplexTR æ•°æ®é›†å¤ç°
python complextr.py
```

## ğŸ”§ é…ç½®è¯´æ˜

### ç»Ÿä¸€åŸºçº¿é…ç½®

ä¸ºç¡®ä¿ä¸åŒ RAG æ–¹æ³•ä¹‹é—´çš„å…¬å¹³æ¯”è¾ƒ,é¡¹ç›®é‡‡ç”¨ç»Ÿä¸€çš„åŸºçº¿é…ç½®ã€‚è¯¦ç»†é…ç½®è¯´æ˜è¯·å‚è€ƒ [graph_baseline.md](graph_baseline.md)ã€‚

#### æ ¸å¿ƒé…ç½®å‚æ•°

| é…ç½®é¡¹ | å€¼ | è¯´æ˜ |
|--------|-----|------|
| **LLM æ¨¡å‹** | Qwen3-32B | æœ¬åœ° VLLM éƒ¨ç½² |
| **LLM Base URL** | `http://localhost:8000/v1` | VLLM API åœ°å€ |
| **LLM Temperature** | 0.0 | ç¡®å®šæ€§è¾“å‡º |
| **LLM Max Token** | 32768 | æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦ |
| **Embedding æ¨¡å‹** | Qwen3-Embedding-8B | æœ¬åœ°æ¨¡å‹ |
| **Embedding è·¯å¾„** | `/workspace/models/Qwen3-Embedding-8B` | æœ¬åœ°è·¯å¾„ |
| **Embedding ç»´åº¦** | 4096 | å‘é‡ç»´åº¦ |
| **Embedding ä¸Šä¸‹æ–‡** | 32768 | æœ€å¤§ä¸Šä¸‹æ–‡ |
| **Chunk Size** | 1200 tokens | æ–‡æœ¬åˆ†å—å¤§å° |
| **Chunk Overlap** | 100 tokens | åˆ†å—é‡å å¤§å° |
| **Max Token for Text Unit** | 12000 tokens | æ–‡æœ¬å•å…ƒæœ€å¤§ token æ•° |

#### Qwen3-32B æ€è€ƒåŠŸèƒ½é…ç½®

DyG-RAG é»˜è®¤ç¦ç”¨ Qwen3-32B çš„æ€è€ƒ(Thinking)åŠŸèƒ½ä»¥æå‡æ€§èƒ½:
- **æ€§èƒ½æå‡**: å“åº”é€Ÿåº¦æå‡çº¦ 20-40%
- **è¾“å‡ºç®€æ´**: ç›´æ¥ç»™å‡ºç­”æ¡ˆ,æ— ä¸­é—´æ¨ç†è¿‡ç¨‹
- **é…ç½®æ–¹å¼**: é€šè¿‡ `extra_body` å‚æ•°è®¾ç½® `enable_thinking: false`

è¯¦è§ [graph_baseline.md - Qwen3-32B æ€è€ƒåŠŸèƒ½é…ç½®](graph_baseline.md#qwen3-32b-æ€è€ƒåŠŸèƒ½é…ç½®)ã€‚

### GraphRAG é…ç½®æ–‡ä»¶

GraphRAG æ–¹æ³•çš„é…ç½®ä½äº `GraphRAG/Option/Method/` ç›®å½•:

```yaml
# ç¤ºä¾‹: HippoRAG.yaml
llm:
  api_type: "open_llm"
  base_url: 'http://localhost:8000/v1'
  model: "qwen3-32b"
  api_key: "EMPTY"
  max_token: 32768
  temperature: 0.0

embedding:
  api_type: "hf"
  model: "/workspace/models/Qwen3-Embedding-8B"
  dimensions: 4096
  max_token_size: 32768
  embed_batch_size: 128

chunk:
  chunk_size: 1200
  chunk_overlap: 100
  token_model: "gpt-3.5-turbo"
```

## ğŸ“š æ•°æ®é›†

### æ”¯æŒçš„æ•°æ®é›†

1. **TimeQA**: æ—¶åºé—®ç­”æ•°æ®é›†,åŒ…å« easy/hard ä¸¤ç§éš¾åº¦çº§åˆ«
2. **TempReason**: æ—¶åºæ¨ç†æ•°æ®é›†,åŒ…å« L2/L3 ä¸¤ç§æ¨ç†æ·±åº¦
3. **ComplexTR**: å¤æ‚æ—¶åºæ¨ç†æ•°æ®é›†

### æ•°æ®é›†æ ¼å¼

é¡¹ç›®æ”¯æŒä¸¤ç§æ•°æ®é›†æ ¼å¼:

#### TempReason æ ¼å¼
```json
{
  "content_num": 15266,
  "questions_num": 16017,
  "contents": [
    {
      "fact_context": "æ–‡æ¡£å†…å®¹...",
      "question_list": [
        {
          "question": "é—®é¢˜?",
          "text_answers": {"text": ["ç­”æ¡ˆ1", "ç­”æ¡ˆ2"]},
          "date": "May 27, 1946",
          "id": "L2_Q367750_P39_0"
        }
      ]
    }
  ]
}
```

#### TimeQA æ ¼å¼
```json
{
  "content_num": 3500,
  "datas": [
    {
      "idx": "/wiki/Knox_Cunningham#P39",
      "context": "æ–‡æ¡£å†…å®¹...",
      "questions_list": [
        {
          "question": "é—®é¢˜?",
          "targets": ["ç­”æ¡ˆ1", "ç­”æ¡ˆ2"],
          "level": "easy"
        }
      ]
    }
  ]
}
```

## ğŸ› ï¸ é«˜çº§ç”¨æ³•

### æ·»åŠ æ–°çš„ QA æ–¹æ³•

1. åœ¨å¯¹åº”æ•°æ®é›†ç›®å½•ä¸‹åˆ›å»ºæ–¹æ³•æ–‡ä»¶å¤¹:
   ```bash
   mkdir -p QA-result/timeqa/YourMethod
   ```

2. å°†ç»“æœä¿å­˜ä¸º `results.json`,æ”¯æŒä»¥ä¸‹æ ¼å¼ä¹‹ä¸€:
   - JSON æ ¼å¼(ç±»ä¼¼ DyG-RAG)
   - JSONL æ ¼å¼(ç±»ä¼¼ HippoRAG)

3. ç¡®ä¿ç»“æœåŒ…å«å¿…è¦å­—æ®µ:
   - `question`: é—®é¢˜æ–‡æœ¬
   - `output` æˆ– `answer`: æ¨¡å‹è¾“å‡º(åŒ…å«åŠ ç²—å®ä½“ `**å®ä½“å**`)
   - `level`(å¯é€‰): éš¾åº¦çº§åˆ«(easy/hard)

4. è¿è¡Œè¯„ä¼°è„šæœ¬:
   ```bash
   python evaluate_qa_results.py
   ```

### è‡ªå®šä¹‰ GraphRAG æ–¹æ³•

1. å¤åˆ¶å¹¶ä¿®æ”¹ç°æœ‰é…ç½®æ–‡ä»¶:
   ```bash
   cp GraphRAG/Option/Method/HippoRAG.yaml GraphRAG/Option/Method/YourMethod.yaml
   ```

2. ä¿®æ”¹é…ç½®å‚æ•°

3. è¿è¡Œè‡ªå®šä¹‰æ–¹æ³•:
   ```bash
   python GraphRAG/main.py -opt Option/Method/YourMethod.yaml -dataset_name timeqa
   ```

## ğŸ“Š è¯„ä¼°æŒ‡æ ‡è¯´æ˜

### æ–‡æœ¬è§„èŒƒåŒ–

åœ¨è®¡ç®— EM å’Œ F1 ä¹‹å‰,ç­”æ¡ˆä¼šç»è¿‡ä»¥ä¸‹è§„èŒƒåŒ–å¤„ç†:
- è½¬ä¸ºå°å†™
- ç§»é™¤å† è¯(a, an, the)
- ç§»é™¤æ ‡ç‚¹ç¬¦å·
- ç§»é™¤ Unicode å­—ç¬¦
- è§„èŒƒåŒ–ç©ºæ ¼

### F1 è®¡ç®—æ–¹æ³•

F1 åˆ†æ•°åŸºäº Token çº§åˆ«çš„é‡å è®¡ç®—:
```
Precision = åŒ¹é…çš„ tokens æ•° / é¢„æµ‹ç­”æ¡ˆçš„ tokens æ•°
Recall = åŒ¹é…çš„ tokens æ•° / æ ‡å‡†ç­”æ¡ˆçš„ tokens æ•°
F1 = 2 * (Precision * Recall) / (Precision + Recall)
```

å¯¹äºæ¯ä¸ªé—®é¢˜,ä¼šè®¡ç®—é¢„æµ‹ç­”æ¡ˆä¸æ‰€æœ‰æ ‡å‡†ç­”æ¡ˆçš„ F1 åˆ†æ•°,å–æœ€å¤§å€¼ã€‚

### è¯„ä¼°ç»“æœç¤ºä¾‹

```markdown
| Method | Dataset | Level | EM (%) | F1 (%) | Questions |
|--------|---------|-------|--------|--------|-----------|
| DyG-RAG | timeqa | easy | 75.00 | 82.50 | 8 |
| DyG-RAG | timeqa | hard | 60.00 | 71.25 | 8 |
| **DyG-RAG** | **timeqa** | **overall** | **67.50** | **76.88** | **16** |
| HippoRAG | timeqa | easy | 83.33 | 88.75 | 8 |
| HippoRAG | timeqa | hard | 62.50 | 75.00 | 8 |
| **HippoRAG** | **timeqa** | **overall** | **72.92** | **81.88** | **16** |
```

## ğŸ” æ•…éšœæ’é™¤

### é—®é¢˜: æ‰¾ä¸åˆ°ç»“æœæ–‡ä»¶

ç¡®ä¿ç»“æœæ–‡ä»¶è·¯å¾„æ­£ç¡®:
```
QA-result/<dataset>/<method>/results.json
```

### é—®é¢˜: ç­”æ¡ˆæå–å¤±è´¥

æ£€æŸ¥è¾“å‡ºä¸­çš„ç­”æ¡ˆæ ¼å¼æ˜¯å¦åŒ…å«åŠ ç²—å®ä½“æ ‡è®° `**å®ä½“å**`ã€‚

### é—®é¢˜: ç¼ºå°‘ ground truth

ç¡®ä¿æ•°æ®é›†æ–‡ä»¶å­˜åœ¨:
```
dataset/<dataset>/test_processed.json
```

### é—®é¢˜: VLLM è¿æ¥å¤±è´¥

1. æ£€æŸ¥ VLLM æœåŠ¡æ˜¯å¦å¯åŠ¨:
   ```bash
   curl http://localhost:8000/v1/models
   ```

2. æ£€æŸ¥ç«¯å£æ˜¯å¦è¢«å ç”¨:
   ```bash
   lsof -i :8000
   ```

3. æŸ¥çœ‹ VLLM æ—¥å¿—æ’æŸ¥é”™è¯¯

### é—®é¢˜: GPU å†…å­˜ä¸è¶³

1. å‡å°‘ tensor_parallel_size
2. é™ä½ max_model_len
3. ä½¿ç”¨é‡åŒ–æ¨¡å‹(å¦‚ int8/int4)
4. è°ƒæ•´ gpu_memory_utilization å‚æ•°

## ğŸ“¦ ä¾èµ–é¡¹

ä¸»è¦ä¾èµ–åŒ…æ‹¬:

- **æ·±åº¦å­¦ä¹ æ¡†æ¶**: `torch>=2.0.0`, `transformers>=4.35.0`
- **å‘é‡å­˜å‚¨**: `faiss-gpu`, `hnswlib`, `nano-vectordb`
- **å›¾è®¡ç®—**: `networkx`, `igraph`, `neo4j`, `graspologic`
- **LLM æ¨ç†**: `vllm>=0.8.4`, `openai`
- **æ–‡æœ¬å¤„ç†**: `sentence-transformers`, `tiktoken`
- **å…¶ä»–**: `pandas`, `numpy`, `scikit-learn`, `pyyaml`

å®Œæ•´ä¾èµ–åˆ—è¡¨è§ [requirements.txt](requirements.txt)ã€‚

å®‰è£…ä¾èµ–:
```bash
pip install -r requirements.txt
```
