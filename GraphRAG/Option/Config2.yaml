llm:
  api_type: "open_llm"  # OpenAI-compatible local LLM (VLLM)
  base_url: 'http://localhost:8000/v1'  # Local VLLM service URL
  model: "qwen3-32b"  # Model name (must match VLLM --served-model-name)
  api_key: "EMPTY"  # Local VLLM doesn't require real API key
  temperature: 0.0  # Deterministic output for reproducibility
  max_token: 4096  # Maximum completion tokens (留空间给输入，模型上下文窗口为32768)
  timeout: 600  # Timeout in seconds
  enable_thinking: false  # Set to false to disable thinking mode (for DeepSeek-R1, QwQ models)

embedding:
  api_type: "hf"  # HuggingFace / SentenceTransformer
  # base_url: "https://cfcus02.opapi.win/v1"  # or forward url / other llm url
  api_key: "EMPTY"  # Not required for local models
  model: "/workspace/models/Qwen3-Embedding-8B"  # Local Qwen3-Embedding-8B model path
  cache_dir: ""
  dimensions: 4096  # Qwen3-Embedding-8B output dimension
  max_token_size: 32768  # Qwen3-Embedding-8B supports 32k context
  embed_batch_size: 128  # Batch size for embedding generation
  embedding_func_max_async: 16  # Maximum async embedding requests
 
data_root:  "/workspace/ETE-Graph/dataset" # Root directory for data



working_dir: ./ # Result directory for the experiment
exp_name: "default"  # Experiment name
#